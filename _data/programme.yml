keynotes:
  - name: Prof. Sanja Fidler
    id: keynote-1
    img: /assets/images/mugshots/sanja_fidler.jpg
    url: "https://www.cs.utoronto.ca/~fidler/"
    title: "AI for 3D Content Creation"
    job: Faculty at University of Toronto and a Director of AI at NVIDIA
    abstract: "3D content is key in several domains such as architecture, film, gaming, and robotics. However, creating 3D content can be very time consuming -- the artists need to sculpt high quality 3d assets, compose them into large worlds, and bring these worlds to life by writing behaviour models that “drives” the characters around in the world. In this talk, I’ll discuss some of our recent efforts on introducing automation in the 3D content creation process using A.I."
    slides-id: 38934739
  - name: Prof. Laura Leal-Taixé
    id: keynote-4
    img: /assets/images/mugshots/lealtaixe.jpg
    url: "https://dvl.in.tum.de/team/lealtaixe/"
    title: "Multiple Object Tracking: Promising Directions and Data Privacy"
    job: Faculty at the Technical University of Munich
    abstract: "Is the performance on multiple object tracking benchmarks saturating? What seem to be promising new research directions? I will first analyze the performance of recent methods, and show how powerful a simple object detector regressor can be for MOT. This analysis will uncover the main challenges that as a community we are still not tackling.
I will then move towards end-to-end learning for MOT, and explain how graph neural networks can open the path to new research directions. Finally, I will show how computer vision tools can help us in handling data privacy in MOT benchmarks."
  - name: Prof. Kate Saenko
    id: keynote-3 
    img: /assets/images/mugshots/kate_saenko.png
    url: "http://ai.bu.edu/ksaenko.html"
    title: "Mitigating Dataset Bias"
    job: Faculty at Boston University and MIT-IBM Watson AI Lab
    abstract: "Deep Learning has made exciting progress on many computer vision problems such as object recognition in images and video. However, it has relied on large datasets that can be expensive and time-consuming to collect and label. Datasets can also suffer from “dataset bias,” which happens when the training data is not representative of the future deployment domain. Dataset bias is a major problem in computer vision -- even the most powerful deep neural networks fail to generalize to out-of-sample data. A classic example of this is when a network trained to classify handwritten digits fails to recognize typed digits, but this problem happens in many situations, such as new geographic locations, changing demographics, and simulation-to-real learning. Can we solve dataset bias with only a limited amount of supervision? Yes, this is possible under some assumptions. I will give an overview of current solutions based on domain adaptation of deep learning models and point out several assumptions they make and situations they fail to handle. I will also describe recent efforts to improve adaptation by using unlabeled data to learn better features, with ideas from self-supervised learning."
  - name: Prof. Andrew Davison
    id: keynote-2
    img: /assets/images/mugshots/andy_davison.jpg
    url: "https://www.doc.ic.ac.uk/~ajd/"
    title: "Towards Graph-Based Spatial AI"
    job: Faculty at Imperial College and Head of the Dyson Robitics Lab
    slides-id: 38934742
    abstract: "To enable the next generation of smart robots and devices which can
truly interact with their environments, Simultaneous Localisation and
Mapping (SLAM) will progressively develop into a vision-driven
geometric and semantic `Spatial AI' perception capability which gives
devices the real-time dynamic model in which to reason in intuitive
and intelligent ways about their actions.  A fundamental issue is the
algorithmic architecture which will enable estimation and machine
learning components to come together to enable efficient, incremental
updating of scene representation, and I believe that graph strucures
where storage and computation come together will be the key. New
computing and sensing hardware is now becoming available which makes
research in this direction a reality."


