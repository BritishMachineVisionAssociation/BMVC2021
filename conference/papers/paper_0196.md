---
layout: default_paper
id: 196
order: 118
poster_session: 3
session_id: 8
title: "What do CNNs gain by imitating the visual development of primate infants?"
authors:
  - author: "Shantanu Jaiswal (Agency for Science, Technology and Research )"
  - author: "Dongkyu Choi (Agency for Science, Technology and Research)"
  - author: "Basura Fernando (Agency for Science, Technology and Research, ASTAR, Singapore)"
all_authors: "Shantanu Jaiswal, Dongkyu Choi and Basura Fernando"
code: ""
keywords:
  - word: "Biologically inspired vision"
  - word: "Primate visual development"
  - word: "Greedy layer-wise training"
  - word: "Supervised training approaches"
paper: "papers/0196.pdf"
supp: "supp/0196_supp.zip"
abstract: "Deep convolutional neural networks have emerged as strong candidates for a model of human vision, often outperforming competing models on both computer vision benchmarks and computational neuroscience benchmarks of neural response correspondence. The design of these models has undergone several refinements in recent years drawing on both statistical and cognitive insights and, in the process, shown increasing correspondence to primate visual processing representations. However, their training methodology still remains in contrast to the process of primate visual development, and we believe that it can benefit from being more aligned with this natural process. Primate visual development is characterized by low visual acuity and colour sensitivity as well as high plasticity and neuronal growth in the first year of infancy, prior to the development of specific visual-cognitive functions such as visual object recognition. In this work, we investigate the synergy between the gradual variation in the distribution of visual input and the concurrent growth of a statistical model of vision on the task of large-scale object classification, and discuss how it may yield better approaches to training deep convolutional neural networks. The experiments we performed across multiple object classification benchmarks indicate that a growing statistical model trained with a gradually varying visual input distribution converges to a better generalization at a faster rate than traditional, more static training setups."
slides-id: 38933917
channel-id: "paper_118_P3_id_0196"
---
