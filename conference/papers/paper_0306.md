---
layout: default_paper
id: 306
order: 74
poster_session: 2
session_id: 5
title: "Uncovering Hidden Challenges in Query-Based Video Moment Retrieval"
authors:
  - author: "Mayu Otani (CyberAgent, Inc.)"
  - author: "Yuta Nakashima (Osaka University)"
  - author: "Esa Rahtu (Tampere University)"
  - author: "Janne Heikkila (University of Oulu, Finland)"
all_authors: "Mayu Otani, Yuta Nakashima, Esa Rahtu and Janne Heikkila"
code: "https://github.com/mayu-ot/hidden-challenges-MR"
keywords:
  - word: "video moment retrieval"
  - word: "temporal sentence grounding"
  - word: "dataset analysis"
  - word: "negative result"
  - word: ""
paper: "papers/0306.pdf"
supp: "supp/0306_supp.pdf"
abstract: "The query-based moment retrieval is a problem of localising a specific clip from an untrimmed video according a query sentence. This is a challenging task that requires interpretation of both the natural language query and the video content. Like in many other areas in computer vision and machine learning, the progress in query-based moment retrieval is heavily driven by the benchmark datasets and, therefore, their quality has significant impact on the field. In this paper, we present a series of experiments assessing how well the benchmark results reflect the true progress in solving the moment retrieval task. Our results indicate substantial biases in the popular datasets and unexpected behaviour of the state-of-the-art models. Moreover, we present new sanity check experiments and approaches for visualising the results. Finally, we suggest possible directions to improve the temporal sentence grounding in the future. "
slides-id: 38933945
channel-id: "paper_074_P2_id_0306"
---
